<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins">
  <meta property="og:title" content="Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins"/>
  <meta property="og:description" content="Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins"/>
  <meta property="og:url" content="./index.html"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.jpg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="static/js/video-comparison.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-fullhd">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title publication-title">
              <span style="font-size: 2.5rem;">Prompting with the Future: Open-World</span><br>
              <span style="font-size: 2.5rem;">Model Predictive Control with Interactive Digital Twins</span>
            </h1>
            <h3 class="title is-4 conference-authors"><a target="_blank" href="https://roboticsconference.org/">RSS 2025</a></h3>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://tritiumr.github.io/" target="_blank">Chuanruo Ning</a>,</span>
                <span class="author-block">
                  <a href="https://kuanfang.github.io/" target="_blank">Kuan Fang</a><sup>†</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.cs.cornell.edu/~weichiu/" target="_blank">Wei-Chiu Ma</a><sup>†</sup>,</span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Cornell University</span>
                    <span class="eql-cntrb"><small><br><sup>†</sup>Equal advising</small></span>
                  </div>

                  <!-- <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="http://arxiv.org/abs/2506.13761" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->
                  <span class="link-block">
                    <a href="http://arxiv.org/abs/2506.13761" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://github.com/TritiumR/Prompting-with-the-Future" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-medium-wide">
    <div class="hero-body">
      <video poster="" id="teaser" autoplay muted loop height="70%">
        <!-- Your video here -->
        <source src="static/videos/teaser.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle">
        We propose Prompting with the Future, a <b>model predictive control</b> framework for open-world manipulation.
        We build <b>interactive digital twins as dynamic models</b> to provide outcomes of cadidate actions. 
        The <b>VLM acts as a cost function</b> to evaluate the results of candidate actions to guide the planning.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Open-world robotic manipulation requires robots to perform novel tasks described by free-form language in unstructured settings. While vision-language models (VLMs) offer strong high-level semantic reasoning, they lack the fine-grained physical insight needed for precise low-level control. To address this gap, we introduce Prompting-with-the-Future, a model-predictive control framework that augments VLM-based policies with explicit physics modeling. Our framework builds an interactive digital twin of the workspace from a quick handheld video scan, enabling prediction of future states under candidate action sequences. Instead of asking the VLM to predict actions or results by reasoning dynamics, the framework simulates diverse possible outcomes, renders them as visual prompts with adaptively selected camera viewpoints that expose the most informative physical context. A sampling-based planner then selects the action sequence that the VLM rates as best aligned with the task objective. We validate Prompting-with-the-Future on eight real-world manipulation tasks involving contact-rich interaction, object reorientation, and tool use, demonstrating significantly higher success rates than state-of-the-art VLM-based control methods. Through ablation studies, we further analyze the performance and demonstrate that explicitly modeling physics, while still leveraging VLM semantic strengths, is essential for robust manipulation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Added text box -->
<!-- <div class="has-text-centered mb-5">
  <p class="is-size-3 has-text-weight-bold">
    Motivation
  </p>
</div> -->

<!-- Added text box -->
<!-- <div class="has-text-centered mb-5">
  <p class="is-size-4 has-text-weight-bold">
    Open-world manipulation presents unique challenges.<br> 
    For example, could you choose the correct tossing action to hit the pigs?
  </p>
</div> -->

<!-- <section class="hero is-small" id="multiple-choice">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-10 has-text-centered">

          <figure id="mc-holder" class="mc-holder">
            <img id="mc-thumb"
                 src="static/images/prompt-1.png"
                 alt="Question thumbnail">
            <video id="mc-video"
                   class="is-hidden"
                   controls
                   playsinline></video>
          </figure>

          <div id="mc-choices" class="buttons is-centered mt-4">
            <button class="button is-light" data-video="static/videos/A.mp4">A. Direction: +0.37, +0.93, +0.07, speed: 1.6m/s</button>
            <button class="button is-light" data-video="static/videos/B.mp4">B. Direction: +0.37, +0.93, +0.07, speed: 1.3m/s</button>
            <button class="button is-light" data-video="static/videos/C.mp4">C. Direction: +0.41, +0.90, -0.16, speed: 1.5m/s</button>
            <button class="button is-light" data-video="static/videos/D.mp4">D. Direction: +0.41, +0.90, -0.16, speed: 1.0m/s</button>
          </div>

        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- Added text box -->
<!-- <div class="has-text-centered mb-5">
  <p class="is-size-4 has-text-weight-bold">
    Feels hard?<br>But that's what we require the VLM to do for manipulation.
  </p>
</div> -->

<!-- Added text box -->
<!-- <div class="has-text-centered mb-5">
  <p class="is-size-4 has-text-weight-bold">
    How about this?<br>Given the outcomes of different actions, choose the best one.
  </p>
</div> -->

<!-- ── Multiple‑Choice Demo Two ────────────────────────────────── -->
<!-- <section class="hero is-small" id="multiple-choice-two">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-10 has-text-centered">

          <figure id="mc-holder-two" class="mc-holder">
            <img id="mc-thumb-two"
                 src="static/images/prompt-2.png"
                 alt="Question thumbnail">
            <video id="mc-video-two"
                   class="is-hidden"
                   controls
                   playsinline></video>
          </figure>

          <div id="mc-choices-two" class="buttons is-centered mt-4">
            <button class="button is-light" data-video="static/videos/C.mp4">Result A</button>
            <button class="button is-light" data-video="static/videos/A.mp4">Result B</button>
            <button class="button is-light" data-video="static/videos/B.mp4">Result C</button>
            <button class="button is-light" data-video="static/videos/D.mp4">Result D</button>
          </div>

        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- Added text box -->
<!-- <div class="has-text-centered mb-5">
  <p class="is-size-4 has-text-weight-bold">
    Much easier? Therefore, we propose to perform open-world manipulation in this model predictive control framework.
  </p>
</div> -->

<!-- Added text box -->
<div class="has-text-centered mb-5">
  <p class="is-size-3 has-text-weight-bold">
    Building interactive digital twins
  </p>
</div>

<!-- Framework 1 video-->
<section class="hero teaser">
  <div class="container is-medium-wide">
    <div class="hero-body">
      <video poster="" id="framework_1" autoplay loop muted>
        <!-- Your video here -->
        <source src="static/videos/framework_1.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle">
        Starting from a video scan of the environment, we construct an interactive digital twin that combines mesh-based simulation and Gaussian-based rendering. 
        We segment the movable objects in both representations, enabling physically grounded simulation and photo-realistic rendering.
      </h2>
    </div>
  </div>
</section>
<!-- End framework 1 video -->

<!-- Added text box -->
<div class="has-text-centered mb-5">
  <p class="is-size-3 has-text-weight-bold">
    Sampling-based motion planning
  </p>
</div>

<!-- Framework 2 video-->
<section class="hero teaser">
  <div class="container is-medium-wide">
    <div class="hero-body">
      <video poster="" id="framework_2" autoplay loop muted>
        <!-- Your video here -->
        <source src="static/videos/framework_2.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle">
        With the interactive digital twin, we can simulate outcomes of candidate actions and render the resulting states. 
        The VLM adaptively selects the most informative view for rendering and evaluates the predicted outcomes for sampling-based motion planning.
      </h2>
    </div>
  </div>
</section>
<!-- End framework 1 video -->


<!-- Added text box -->
<div class="has-text-centered mb-5">
  <p class="is-size-3 has-text-weight-bold">
    Interactive digital twins
  </p>
</div>

<!-- Video Comparison -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div style="display: flex; gap: 20px; justify-content: center;">
        <div class="video-comparison-container" style="width: 33%;">
          <div class="video-wrapper">
            <div class="video-slide-container">
              <div class="video-slide">
                <video id="bird_twin1" class="comparison-video" autoplay muted loop>
                  <source src="static/videos/bird_mesh.mp4" type="video/mp4">
                </video>
                <video id="bird_twin2" class="comparison-video" autoplay muted loop>
                  <source src="static/videos/bird_gaussian.mp4" type="video/mp4">
                </video>
                <div class="division-line" id="birdDivisionLine" style="background-color: #808080;"></div>
              </div>
            </div>
          </div>
        </div>
        <div class="video-comparison-container" style="width: 33%;">
          <div class="video-wrapper">
            <div class="video-slide-container">
              <div class="video-slide">
                <video id="tune_real" class="comparison-video" autoplay muted loop>
                  <source src="static/videos/tune_real.mp4" type="video/mp4">
                </video>
                <video id="tune_twin" class="comparison-video" autoplay muted loop>
                  <source src="static/videos/tune_gaussian.mp4" type="video/mp4">
                </video>
                <div class="division-line" id="plantDivisionLine" style="background-color: #808080;"></div>
                
              </div>
            </div>
          </div>
          <!-- Play‑with‑sound trigger -->
          <button class="play-sound-btn button is-small is-primary">
            ▶ Play with sound
          </button>
        </div>
        
        <div class="video-comparison-container" style="width: 33%;">
          <div class="video-wrapper">
            <div class="video-slide-container">
              <div class="video-slide">
                <video id="plant_twin1" class="comparison-video" autoplay muted loop>
                  <source src="static/videos/plant_mesh.mp4" type="video/mp4">
                </video>
                <video id="plant_twin2" class="comparison-video" autoplay muted loop>
                  <source src="static/videos/plant_gaussian.mp4" type="video/mp4">
                </video>
                <div class="division-line" id="plantDivisionLine" style="background-color: #808080;"></div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<h2 class="subtitle has-text-centered">
</br>
  The interactive digital twins closely resemble the real world, modeling the dynamics and providing photo-realistic rendering.
</h2>
<!-- End video comparison -->

<!-- Added text box -->
<div class="has-text-centered mb-5">
  <p class="is-size-3 has-text-weight-bold">
    Open-world manipulation
  </p>
</div>

<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <video poster="" id="video1" autoplay controls muted loop height="100%" style="border-radius: 15px;">
            <source src="static/videos/pl.mp4"
            type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Water the plant
          </h2>
        </div>
        <div class="item">
          <video poster="" id="video2" autoplay controls muted loop height="100%" style="border-radius: 15px;">
            <source src="static/videos/spo.mp4"
            type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Clean up
          </h2>
        </div>
        <div class="item">
          <video poster="" id="video3" autoplay controls muted loop height="100%" style="border-radius: 15px;">
            <source src="static/videos/dr.mp4"
            type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Play the drum
          </h2>
        </div>
        <div class="item">
          <video poster="" id="video4" autoplay controls muted loop height="100%" style="border-radius: 15px;">
            <source src="static/videos/sh.mp4"
            type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Pair up the shoes
          </h2>
        </div>
        <div class="item">
          <video poster="" id="video5" autoplay controls muted loop height="100%" style="border-radius: 15px;">
            <source src="static/videos/spa.mp4"
            type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Press the space bar
          </h2>
        </div>
        <div class="item">
          <video poster="" id="video6" autoplay controls muted loop height="100%" style="border-radius: 15px;">
            <source src="static/videos/ch.mp4"
            type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Unplug the charger
          </h2>
        </div>
        <div class="item">
          <video poster="" id="video7" autoplay controls muted loop height="100%" style="border-radius: 15px;">
            <source src="static/videos/ba.mp4"
            type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Put cubumber into the basket
          </h2>
        </div>
        <div class="item">
          <video poster="" id="video8" autoplay controls muted loop height="100%" style="border-radius: 15px;">
            <source src="static/videos/tu.mp4"
            type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Play the lowest tune
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<h2 class="subtitle has-text-centered">
</br>
  Prompting with the Future can perform diverse open-world manipulation tasks without any task-specific training or examples.
</h2>
<!-- End video carousel -->



<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{ning2025prompting,
  title={Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins},
  author={Ning, Chuanruo and Fang, Kuan and Ma, Wei-Chiu},
  booktitle={RSS},
  year={2025}
}</code></pre>
  </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
